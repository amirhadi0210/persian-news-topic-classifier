# Persian News Category Classifier ğŸš€

A production-ready machine learning pipeline for classifying Persian news articles using LinearSVC + TF-IDF. Includes CLI tools, REST API, preprocessing utilities, and deployment configuration.

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-v1.3-orange)
![Status](https://img.shields.io/badge/Status-Production--Ready-green)

**A high-throughput automated content tagging engine designed to reduce manual moderation costs by ~80% while maintaining high data quality via Human-in-the-Loop (HITL) fallbacks.**

---

## ğŸ¯ Business Value & Impact

This system replaces manual categorization of news articles with a machine learning pipeline. It is optimized for speed and reliability in a production environment.

| Metric | Performance | Business Implication |
| :--- | :--- | :--- |
| **Automation Rate** | **~80%** | Only 20% of articles require manual review. |
| **Accuracy (F1)** | **0.80** | High reliability on 17 distinct content categories. |
| **Throughput** | **10k+ / day** | Lightweight architecture allows massive scaling on CPU. |
| **Risk Control** | **Confidence Scoring** | Predictions below **65% confidence** are flagged for human review. |

---

## ğŸ“‚ Repository Structure

The project follows a modular structure separating experimentation (notebooks) from production logic (scripts).

```text
.
â”œâ”€â”€ data/                    # Raw training data and stopwords
â”œâ”€â”€ models/                  # Serialized artifacts (Pipeline + Encoders)
â”œâ”€â”€ src/                     # Configuration and utility modules
â”‚   â””â”€â”€ config.py
â”œâ”€â”€ notebooks/
    â””â”€â”€test.ipynb            # Experimentation, EDA, and Model Training
â”œâ”€â”€ predict.py               # CLI tool for single-instance inference
â”œâ”€â”€ api.py                   # Flask REST API for production deployment
â”œâ”€â”€ requirements.txt         # Project dependencies
â””â”€â”€ README.md                # Project documentation

---

---

## ğŸ“˜ Usage Guide

### ğŸš€ Installation

1. **Clone the repository:**

```bash
git clone https://github.com/<your-username>/<your-repo>.git
cd <your-repo>
```

2. **Install dependencies:**

```bash
pip install -r requirements.txt
```

3. **Verify that the model exists:**

```
models/persian_classifier_v1.pkl
```

If missing, run the training notebook to generate it.

---

## ğŸ–¥ï¸ Command Line Usage (CLI)

Test a single prediction:

```bash
python predict.py "ØªÛŒÙ… Ù…Ù„ÛŒ ÙÙˆØªØ¨Ø§Ù„ Ø§ÛŒØ±Ø§Ù† Ø¯Ø± Ø¬Ø§Ù… Ø¬Ù‡Ø§Ù†ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø®ÙˆØ¨ÛŒ Ø¯Ø§Ø´Øª"
```

Example Output:

```
Input: ØªÛŒÙ… Ù…Ù„ÛŒ ÙÙˆØªØ¨Ø§Ù„ Ø§ÛŒØ±Ø§Ù† Ø¯Ø± Ø¬Ø§Ù… Ø¬Ù‡Ø§Ù†ÛŒ...
Prediction: ÙˆØ±Ø²Ø´
Confidence: 0.9214
```

---

## ğŸŒ REST API Usage (Production Mode)

Start the API server:

```bash
python api.py
```

Send a request with `curl`:

```bash
curl -X POST http://localhost:5000/predict \
     -H "Content-Type: application/json" \
     -d '{"title": "Ù†Ø±Ø® ØªÙˆØ±Ù… Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØª", "description": "Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø§Ù†Ú© Ù…Ø±Ú©Ø²ÛŒ Ù†Ø´Ø§Ù† Ù…ÛŒØ¯Ù‡Ø¯..."}'
```

Example Response:

```json
{
    "category": "ØªØ¬Ø§Ø±Øª Ùˆ Ø§Ù‚ØªØµØ§Ø¯",
    "confidence": 0.88,
    "model_version": "v1.2_prod",
    "status": "success"
}
```

---

## ğŸ“Š Model Performance

The classifier uses **LinearSVC + TF-IDF**, effective for sparse Persian text.

* **Cross-Validation F1:** 0.81 (Â±0.016)
* **Held-Out Test F1:** 0.80

### Confusion Matrix

Ensure the file exists in the project root:

```
./figures/confusion_matrix.png
```

---

## ğŸ”§ Preprocessing Pipeline

* Character normalization using Parsivar
* Sentence and word tokenization
* Punctuation and digit removal
* Domain-specific stopword filtering

---

## âš™ï¸ Configuration (`src/config.py`)

|                  Parameter | Description                                     |
| -------------------------: | :---------------------------------------------- |
| `min_confidence_threshold` | Predictions below this threshold trigger review |
|        `fallback_category` | Output class when confidence is too low         |
|              `ngram_range` | TF-IDF n-gram window, default `(1, 3)`          |

---

## ğŸ“ˆ Roadmap

* [ ] Dockerize API for Kubernetes deployment
* [ ] Add Prometheus monitoring for drift detection
* [ ] Upgrade model using ParsBERT for ambiguous cases

---

## ğŸ‘¤ Author

**Amirhadi Souratian**
Data Scientist / ML Engineer


